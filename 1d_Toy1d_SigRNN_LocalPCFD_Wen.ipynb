{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount('/content/drive')\n",
    "sys.path.append('/content/drive/MyDrive/pcf-diffusion-mx_branch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import timestep_embedding, timesteps_to_tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diffusion import DiffusionProcess\n",
    "import torch\n",
    "from diffusion.utils.sde import SDE\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal, Categorical, MixtureSameFamily\n",
    "import torch\n",
    "#device = 'mps'\n",
    "device = 'cuda:0'\n",
    "import random\n",
    "from src.PCF_with_empirical_measure import PCF_with_empirical_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDE-based diffusion models with ToyNet generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_FC(nn.Module):\n",
    "    def __init__(self, data_dim, hidden_dim, num_res_blocks):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.map=nn.Linear(data_dim, hidden_dim)\n",
    "        self.res_blocks = nn.ModuleList(\n",
    "            [self.build_res_block() for _ in range(num_res_blocks)])\n",
    "\n",
    "    def build_linear(self, in_features, out_features):\n",
    "        linear = nn.Linear(in_features, out_features)\n",
    "        return linear\n",
    "\n",
    "    def build_res_block(self):\n",
    "        hid = self.hidden_dim\n",
    "        layers = []\n",
    "        widths =[hid]*4  # [256, 256, 256, 256]\n",
    "        for i in range(len(widths) - 1):\n",
    "            layers.append(self.build_linear(widths[i], widths[i + 1]))\n",
    "            layers.append(nn.SiLU())\n",
    "        return nn.Sequential(*layers) # [batch_size, dim]\n",
    "\n",
    "    def forward(self, x):  # x_t: [batch_size, data_dim]\n",
    "        h=self.map(x)\n",
    "        for res_block in self.res_blocks:\n",
    "            h = (h + res_block(h)) / np.sqrt(2)\n",
    "        return h   # [batch_size, dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyNet(nn.Module):\n",
    "    def __init__(self, data_dim, direction=None):\n",
    "        super(ToyNet, self).__init__()\n",
    "        self.direction = direction\n",
    "\n",
    "        self.time_embed_dim = 128\n",
    "        dim = 256\n",
    "        out_dim = data_dim\n",
    "\n",
    "        self.t_module = nn.Sequential(nn.Linear(self.time_embed_dim, dim), nn.SiLU(), nn.Linear(dim, dim),)\n",
    "        self.x_module = ResNet_FC(data_dim, dim, num_res_blocks=1)\n",
    "        self.out_module = nn.Sequential(nn.Linear(dim,dim), nn.SiLU(), nn.Linear(dim, out_dim),)\n",
    "        \n",
    "    def forward(self, x, t: int or list[int]): # x_t: [batch_size, data_dim]\n",
    "        t = timesteps_to_tensor(t, batch_size=x.shape[0]).to(x.device)\n",
    "        t_emb = timestep_embedding(t, self.time_embed_dim).to(x.device)  # [batch_size, time_embed_dim]\n",
    "\n",
    "        t_out = self.t_module(t_emb) # [batch_size, dim=256]\n",
    "        x_out = self.x_module(x) # [batch_size, dim=256]\n",
    "        out   = self.out_module(x_out+t_out) # [batch_size, out_dim=data_dim]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDEProcess(DiffusionProcess):\n",
    "    def __init__(self, sde_type=\"VP\",\n",
    "                 sde_info={\"VP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"subVP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"VE\": {\"sigma_min\": 0.01, \"sigma_max\": 50}}, \n",
    "                 **kwargs):\n",
    "        super(SDEProcess, self).__init__(**kwargs)\n",
    "        assert self.discrete is False, \"DDPM is only for continuous data\"\n",
    "        self.dt = 1. / self.total_steps # step size\n",
    "        self.sde = SDE(self.total_steps, sde_type, sde_info)\n",
    "        \n",
    "    def forward_one_step(self, x_prev, t):\n",
    "        \"\"\"\n",
    "        Discretized forward SDE process for actual compuatation: \n",
    "        x_{t+1} = x_t + f_t(x_t) * dt + G_t * z_t * sqrt(dt)\n",
    "        \"\"\"\n",
    "        f_t, g_t = self.sde.drifts(x_prev, t-1)\n",
    "        z = torch.randn_like(x_prev)\n",
    "        x_t = x_prev + f_t * self.dt + g_t * z * np.sqrt(self.dt)\n",
    "        return x_t # [N]\n",
    "\n",
    "    \n",
    "    def backward_one_step(self, x_t, t, pred_score, clip_denoised=True):\n",
    "        \"\"\"\n",
    "        Discretized backward SDE process for actual compuatation:\n",
    "        x_{t-1} = x_t - (f_t(x_t) - (G_t)^2 * pred_score) * dt + G_t * z_t * sqrt(dt)\n",
    "        \"\"\"\n",
    "        z = torch.randn_like(x_t).to(device) # [N,d=1]\n",
    "        f_t, g_t = self.sde.drifts(x_t, t)\n",
    "        f_t = f_t.to(device)\n",
    "        x_prev = x_t - (f_t - g_t**2 * pred_score) * self.dt + g_t * z * np.sqrt(self.dt)\n",
    "        if clip_denoised and x_t.ndim > 2:\n",
    "            print('backward_one_step')\n",
    "            x_prev.clamp_(-1., 1.) \n",
    "\n",
    "        return x_prev # [N,d=1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, noise, net):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        x_t = noise # [N,1]\n",
    "        trajs = [x_t]\n",
    "\n",
    "        for t in reversed(range(1, self.total_steps+1)):\n",
    "            pred_score = net(x_t, t)\n",
    "            x_t = self.backward_one_step(x_t, t, pred_score)\n",
    "            trajs.append(x_t)\n",
    "        return x_t, torch.hstack(trajs)\n",
    "    \n",
    "    def forward_sample(self, data): # data: torch.tensor, shape=[N]\n",
    "        trajs = torch.zeros([len(data), self.total_steps+1]) # [N, T+1]\n",
    "        x = data.to(device) # [N]\n",
    "        trajs[:, 0] = x\n",
    "        for t in range(1, self.total_steps+1):\n",
    "            x = self.forward_one_step(x, t) # [N]\n",
    "            trajs[:, t] = x\n",
    "        return x, trajs # [N], [N, T+1]\n",
    "    \n",
    "    def backward_sample(self, noise, net):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        x_t = noise # [N,d=1]\n",
    "        trajs = [x_t]\n",
    "\n",
    "        for t in reversed(range(1, self.total_steps+1)):\n",
    "            pred_score = net(x_t, t)\n",
    "            x_t = self.backward_one_step(x_t, t, pred_score)\n",
    "            trajs.append(x_t)\n",
    "        return x_t, torch.hstack(trajs) # [N,d=1], [N,(T+1)*d]\n",
    "        \n",
    "    def backward_sample_example(self, noise, net):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        noise: torch.tensor, shape=[num_paths, T]\n",
    "        \"\"\"\n",
    "        # noise_start = noise[:, 0]\n",
    "        noise_end = noise[:, -1]\n",
    "        # trajs = [noise_end]\n",
    "        trajs = torch.zeros_like(noise)\n",
    "        trajs[:, -1] = noise_end\n",
    "        for t in reversed(range(1, self.total_steps+1)):\n",
    "            pred_score = net(noise[:,t].unsqueeze(1), t) # [N,d=1]\n",
    "            x_t = self.backward_one_step(noise[:,t].unsqueeze(1), t, pred_score)\n",
    "            trajs[:,t-1] = x_t.squeeze()\n",
    "        return x_t, trajs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution\n",
    "mix = Categorical(torch.ones(2,))\n",
    "comp = Normal(torch.tensor([0 - 2., 0 + 2.]).to(device), torch.tensor([.5, .5]).to(device))\n",
    "data_dist = MixtureSameFamily(mix, comp)\n",
    "\n",
    "num_paths = 32\n",
    "print(type(data_dist))  # <class 'torch.distributions.mixture_same_family.MixtureSameFamily'>\n",
    "print(data_dist.batch_shape)  # torch.Size([2])\n",
    "print(data_dist.event_shape)  # torch.Size([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_net = ToyNet(data_dim=1).to(device)\n",
    "total_steps = 100\n",
    "num_paths = 32\n",
    "diffusion = SDEProcess(discrete=False, total_steps=total_steps, sde_type=\"VP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x0, diffusion_process, score_net, t):\n",
    "    #f_t is not involved in the score matching loss soe input zeros for the 1st argument.\n",
    "    #\n",
    "    _, g_t = diffusion_process.sde.drifts(torch.zeros_like(x0), t)\n",
    "    \n",
    "    # Eq 29 in Score based diffusion model (Yang Song 2021 ICLR)\n",
    "    mean, std = diffusion_process.sde.perturbation_kernel(x0, t)\n",
    "    z = torch.randn_like(x0)\n",
    "\n",
    "    x_t = mean + std * z  # x_t is perturbed x_0\n",
    "    pred_score = score_net(x_t, t)\n",
    "    target = -z / std   # Since desired derivative of the given kernel is - (x_t - mean) / std^2\n",
    "    loss = g_t**2 * F.mse_loss(pred_score, target, reduction=\"sum\") / np.prod(x0.size())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data_dist.sample([num_paths]).to(device)\n",
    "x_noise, traj_forward = diffusion.forward_sample(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "opt = torch.optim.Adam(score_net.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Forward process to generate time series\n",
    "    opt.zero_grad()\n",
    "    x0 = data_dist.sample([num_paths]).to(device)\n",
    "    t = np.random.randint(1, total_steps + 1)\n",
    "    loss = loss_function(x0.view(-1 ,1), diffusion, score_net, t)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if(i%50==0):\n",
    "        x0 = data_dist.sample([num_paths]).to(device)\n",
    "        t = np.random.randint(1, total_steps + 1)\n",
    "        loss = loss_function(x0.view(-1 ,1), diffusion, score_net, t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if(i%50==0):\n",
    "        print(i, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.linspace(0, 1, traj_forward.shape[1])\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for line in traj_forward:\n",
    "    plt.plot(xxx, line.cpu(), linewidth=1.0)\n",
    "    plt.title('forward')\n",
    "plt.ylim(-5, 5)\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "x_gen, traj_back = diffusion.sample(torch.randn([num_paths, 1]).to(device), score_net)\n",
    "for line in traj_back:\n",
    "    plt.plot(xxx, line.cpu(), linewidth=1.0)\n",
    "    plt.title('backward')\n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local PCFD as loss function as ToyNet as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcf = PCF_with_empirical_measure(8, 5, 1, add_time=True)\n",
    "pcf = pcf.to(device)\n",
    "num_paths = 64\n",
    "G_opt = torch.optim.Adam(score_net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "D_opt = torch.optim.Adam(pcf.parameters(), lr=5e-3, betas=(0.9, 0.999))\n",
    "n_Dstep_per_Gstep = 10\n",
    "n_Gstep_per_Dstep = 1\n",
    "t_max_step = 80\n",
    "\n",
    "num_epochs = 5\n",
    "ts_length = 20\n",
    "forecast_length = 20\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    x_data = data_dist.sample([num_paths]).to(device) # [N]\n",
    "    x_noise, traj_forward = diffusion.forward_sample(x_data) # [N, total_steps+1]\n",
    "    traj_forward = traj_forward.to(device) # [N, total_steps+1]\n",
    "    traj_forward_flip = torch.fliplr(traj_forward)\n",
    "             \n",
    "    # train the PCF network as a discriminator. We want PCF has a great ablitily to distinguish the real data and the generated data. \n",
    "    # So we train the PCF to maxmise the distance between the real data and the generated data.\n",
    "   \n",
    "        #x_gen, traj_back = diffusion.backward_sample(torch.randn([num_paths, 1]).to(device), score_net)\n",
    "        #x_gen, traj_back = diffusion.backward_sample(x_noise.to(device), score_net)\n",
    "\n",
    "    for j in range(n_Gstep_per_Dstep):  \n",
    "        with torch.no_grad():\n",
    "            x_gen, traj_back = diffusion.backward_sample_example(traj_forward.to(device), score_net)\n",
    "            t = torch.randint(t_max_step, (ts_length,)).to(device)    \n",
    "    \n",
    "            x_real=traj_forward_flip.view([-1,total_steps+1, 1]) # [N, total_steps+1, 1]\n",
    "            x_fake = traj_back.view([-1, total_steps+1, 1]) # [N, total_steps+1, 1]\n",
    "        G_loss = 0\n",
    "        for t1 in range(ts_length):\n",
    "            G_loss = G_loss + pcf.distance_measure(x_real[:, [t1, t1+forecast_length]], \n",
    "                                x_fake[:, [t1,  t1+forecast_length]], Lambda=0.1) \n",
    "        G_loss = G_loss/ts_length\n",
    "        G_opt.zero_grad()\n",
    "        G_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(score_net.parameters(), 0.05)\n",
    "\n",
    "        G_opt.step()\n",
    "        pcf.eval()  # Set PCF model to evaluation mode\n",
    "        print(j,  G_loss.item())\n",
    "        \n",
    "    for j in range(n_Dstep_per_Gstep):\n",
    "        with torch.no_grad():\n",
    "            x_data = data_dist.sample([num_paths]).to(device)\n",
    "            x_noise, traj_forward = diffusion.forward_sample(x_data)\n",
    "            traj_forward = traj_forward.to(device)\n",
    "            x_gen, traj_back = diffusion.backward_sample(torch.randn([num_paths, 1]).to(device), score_net) \n",
    "        traj_forward_flip = torch.fliplr(traj_forward)\n",
    "       # G_loss =  pcf.distance_measure(traj_forward_flip.view([-1, total_steps+1, 1]), \n",
    "                               # traj_back.view([-1, total_steps+1, 1]), Lambda=0) \n",
    "           \n",
    "        x_real=traj_forward_flip.view([-1,total_steps+1, 1])\n",
    "        x_fake = traj_back.view([-1, total_steps+1, 1])\n",
    "        pcf.train()  # Set PCF model to training mode\n",
    "    #D_loss = -pcf.distance_measure(traj_forward_flip.view([-1,  total_steps+1, 1]), \n",
    "                               # traj_back.view([-1, total_steps+1, 1]), Lambda=0.0) \n",
    "        t = torch.randint(t_max_step, (ts_length,)).to(device) \n",
    "        D_loss = 0\n",
    "        for t1 in range(ts_length):\n",
    "            D_loss = D_loss - pcf.distance_measure(x_real[:, [t1, t1+forecast_length]], \n",
    "                                x_fake[:, [t1,  t1+forecast_length]], Lambda=0.1) \n",
    "        D_loss =  D_loss/ts_length\n",
    "\n",
    "        D_opt.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        pcf.eval()  # Set PCF model to evaluation mode\n",
    "        print(j, D_loss.item())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local PCFD as loss function and SigRNN as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dims: Tuple[int]):\n",
    "      super().__init__()      \n",
    "      blocks = []\n",
    "      input_dim_block = input_dim\n",
    "\n",
    "      for hidden_dim in hidden_dims:\n",
    "          blocks.append(nn.Linear(input_dim_block, hidden_dim))\n",
    "          blocks.append(nn.PReLU())\n",
    "          input_dim_block = hidden_dim\n",
    "      blocks.append(nn.Linear(input_dim_block, output_dim))\n",
    "      self.network = nn.Sequential(*blocks)\n",
    "      self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, *args):\n",
    "      x = torch.cat(args, -1)\n",
    "      out = self.network(x)\n",
    "      return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.create_residual_connection = True if input_dim == output_dim else False\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.activation(self.linear(x))\n",
    "        if self.create_residual_connection:\n",
    "            y = x + y\n",
    "        return y\n",
    "\n",
    "class ResFNN(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dims: Tuple[int], flatten: bool = False):\n",
    "        \"\"\"\n",
    "        Feedforward neural network with residual connection.\n",
    "        Args:\n",
    "            input_dim: integer, specifies input dimension of the neural network\n",
    "            output_dim: integer, specifies output dimension of the neural network\n",
    "            hidden_dims: list of integers, specifies the hidden dimensions of each layer.\n",
    "                in above definition L = len(hidden_dims) since the last hidden layer is followed by an output layer\n",
    "        \"\"\"\n",
    "        super(ResFNN, self).__init__()\n",
    "        blocks = list()\n",
    "        self.input_dim = input_dim\n",
    "        self.flatten = flatten\n",
    "        input_dim_block = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            blocks.append(ResidualBlock(input_dim_block, hidden_dim))\n",
    "            input_dim_block = hidden_dim\n",
    "        blocks.append(nn.Linear(input_dim_block, output_dim))\n",
    "        self.network = nn.Sequential(*blocks)\n",
    "        self.blocks = blocks\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.flatten:\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "        out = self.network(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepGenerator(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, num_layers, output_dim=1):\n",
    "    super(OneStepGenerator, self).__init__()\n",
    "\n",
    "    self.input_dim = input_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.num_layers = num_layers\n",
    "    self.output_dim = output_dim\n",
    "    self.time_embed_dim=128\n",
    "\n",
    "    # self.rnn = nn.Sequential(FFN(input_dim = hidden_dim+1+2*input_dim,\n",
    "    #                               output_dim = hidden_dim,\n",
    "    #                               hidden_dims = [hidden_dim, hidden_dim]),  # Two hidden layers, each with hidden_dim units\n",
    "    #                               nn.SiLU()\n",
    "    #                         )\n",
    "    # self.linear = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "    # self.initial_nn = nn.Sequential(ResFNN(input_dim=input_dim,\n",
    "    #                                         output_dim=hidden_dim,\n",
    "    #                                         hidden_dims=[hidden_dim, hidden_dim]),\n",
    "    #                                 nn.SiLU()\n",
    "    #                                 )\n",
    "    \n",
    "    self.t_module = nn.Sequential(nn.Linear(self.time_embed_dim, self.hidden_dim), nn.SiLU(), nn.Linear(self.hidden_dim, self.hidden_dim),)\n",
    "    self.eps_module = ResNet_FC(2*input_dim, hidden_dim, num_res_blocks=1)\n",
    "    self.x_module = nn.Sequential(ResFNN(input_dim=input_dim, output_dim=hidden_dim, hidden_dims=[hidden_dim, hidden_dim]), nn.SiLU())\n",
    "    self.out_module = nn.Sequential(nn.Linear(hidden_dim,hidden_dim), nn.SiLU(), nn.Linear(hidden_dim, output_dim),)\n",
    "\n",
    "  def forward(self, x_t, t, eps): # noise: [N,d=1]\n",
    "    t = timesteps_to_tensor(t, batch_size=x_t.shape[0]).to(x_t.device)\n",
    "    t_emb = timestep_embedding(t, self.time_embed_dim).to(x_t.device)  # [batch_size, time_embed_dim]\n",
    "    t_out = self.t_module(t_emb).to(x_t.device)  # [batch_size, hidden_dim]\n",
    "    eps_out = self.eps_module(eps).to(x_t.device) # [batch_size, hidden_dim]\n",
    "    x_out = self.x_module(x_t).to(x_t.device) # [batch_size, hidden_dim]\n",
    "    out = self.out_module(x_out + t_out + eps_out).to(x_t.device) # [batch_size, out_dim=data_dim]\n",
    "    return out # [N,output_dim=1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigRNNDiffusion(DiffusionProcess):\n",
    "    def __init__(self, sde_type=\"VP\",\n",
    "                 sde_info={\"VP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"subVP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"VE\": {\"sigma_min\": 0.01, \"sigma_max\": 50}},\n",
    "                 c_total_steps = 20,\n",
    "                 **kwargs):\n",
    "        super(SigRNNDiffusion, self).__init__(**kwargs)\n",
    "        assert self.discrete is False, \"DDPM is only for continuous data\"\n",
    "        self.c_total_steps = c_total_steps\n",
    "        self.dt = 1. / self.total_steps # step size\n",
    "        self.c_dt = 1. / self.c_total_steps\n",
    "        self.sde = SDE(self.total_steps, sde_type, sde_info)\n",
    "\n",
    "    def forward_one_step(self, x_prev, t):\n",
    "        \"\"\"\n",
    "        Discretized forward SDE process for actual compuatation:\n",
    "        x_{t+1} = x_t + f_t(x_t) * dt + G_t * z_t * sqrt(dt)\n",
    "        \"\"\"\n",
    "        f_t, g_t = self.sde.drifts(x_prev, t-1)\n",
    "        z = torch.randn_like(x_prev)\n",
    "        x_t = x_prev + f_t * self.dt + g_t * z * np.sqrt(self.dt)\n",
    "        return x_t # [N]\n",
    "\n",
    "    def forward_sample(self, data): # data: torch.tensor, shape=[N]\n",
    "        trajs = torch.zeros([len(data), self.total_steps+1]) # [N,T+1]\n",
    "        x = data.to(device) # [N]\n",
    "        trajs[:, 0] = x\n",
    "        for t in range(1, self.total_steps+1):\n",
    "            x = self.forward_one_step(x, t) # [N]\n",
    "            trajs[:, t] = x\n",
    "        return x, trajs # [N]:the last step, [N,T+1]\n",
    "\n",
    "    def sample_eps(self, batch_size, input_dim, c_dt):\n",
    "      # generate i.i.d. d=input_dim joint Gaussian rvs with defined covariance matrix\n",
    "      eps = []\n",
    "      for _ in range(input_dim):\n",
    "        cov_matrix = torch.tensor([[c_dt, (c_dt**2/2)],\n",
    "                                [(c_dt**2/2), (c_dt**3/3)]])\n",
    "        m = MultivariateNormal(loc=torch.zeros(2), covariance_matrix=cov_matrix)\n",
    "        eps_i = m.sample((batch_size,))\n",
    "        eps.append(eps_i)\n",
    "      eps = torch.cat(eps, dim=1) # [N, 2*input_dim]\n",
    "      return eps.to(device)  # [N, 2*input_dim]\n",
    "\n",
    "    def backward_one_step(self, x_t, t, generator, clip_denoised=True):\n",
    "        eps = self.sample_eps(batch_size=x_t.shape[0], input_dim=x_t.shape[1], c_dt=self.c_dt).to(x_t.device) # [N,2*d=2]\n",
    "        t_tensor = torch.tensor([t], device=x_t.device).unsqueeze(0).repeat(x_t.shape[0], 1) # [N,1]\n",
    "        x_prev = generator(x_t, t_tensor, eps).to(x_t.device)\n",
    "        if clip_denoised and x_t.ndim > 2:\n",
    "            print('backward_one_step')\n",
    "            x_prev.clamp_(-1., 1.)\n",
    "        return x_prev # [N,d=1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, noise, generator):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        # x_t = noise.to(device) # [N,d=1]\n",
    "        x_t = noise # [N,d=1]\n",
    "        trajs = [x_t]\n",
    "        time_c = torch.linspace(self.c_dt,1.,self.c_total_steps)\n",
    "        for t in reversed(time_c):\n",
    "          x_prev = self.backward_one_step(x_t,t,generator) # [N,d=1]\n",
    "          trajs.append(x_prev)\n",
    "        return x_t, torch.hstack(trajs) # [N,d=1], [N,(c_T+1)*(d=1)]\n",
    "\n",
    "    def backward_sample(self, noise, generator):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        # x_t = noise.to(device) # [N,d=1]\n",
    "        x_t = noise # [N,d=1]\n",
    "        trajs = [x_t]\n",
    "        time_c = torch.linspace(self.c_dt,1.,self.c_total_steps)\n",
    "        for t in reversed(time_c):\n",
    "          x_prev = self.backward_one_step(x_t,t,generator) # [N,d=1]\n",
    "          trajs.append(x_prev)\n",
    "        return x_t, torch.hstack(trajs) # [N,d=1], [N,(c_T+1)*(d=1)]\n",
    "\n",
    "    def backward_sample_example(self, noise, generator):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        noise: torch.tensor, shape=[num_paths, T]\n",
    "        \"\"\"\n",
    "        noise_end = noise[:, -1].to(device) #[N]\n",
    "        trajs = torch.zeros_like(noise).to(device) #[N,T]\n",
    "        trajs[:, -1] = noise_end\n",
    "        time_incre = torch.linspace(self.c_dt, 1., self.c_total_steps).to(device)\n",
    "        time_index = torch.linspace(1, self.c_total_steps, self.c_total_steps).to(device)\n",
    "        for idx, t in reversed(list(zip(time_index, time_incre))):\n",
    "            x_t = self.backward_one_step(noise[:, int(idx)].unsqueeze(1).to(device), t, generator) # [N,d=1]\n",
    "            trajs[:, int(idx)-1] = x_t.squeeze()\n",
    "        return x_t, trajs # [N,d=1], [N,T]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 20\n",
    "c_total_steps = 20\n",
    "\n",
    "pcf = PCF_with_empirical_measure(8, 5, 1, add_time=True)  # PCFD\n",
    "pcf = pcf.to(device)\n",
    "\n",
    "# generator = sigRNNGenerator(input_dim=1, hidden_dim=128, num_layers=1, output_dim=1)\n",
    "generator = OneStepGenerator(input_dim=1, hidden_dim=128, num_layers=1, output_dim=1).to(device)\n",
    "generator = generator.to(device)\n",
    "diffusion_sigrnn = SigRNNDiffusion(discrete=False, total_steps=total_steps, sde_type=\"VP\", c_total_steps=c_total_steps)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "G_opt = torch.optim.Adam(generator.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "D_opt = torch.optim.Adam(pcf.parameters(), lr=5e-3, betas=(0.9, 0.999))\n",
    "n_Dstep_per_Gstep = 5\n",
    "n_Gstep_per_Dstep = 5\n",
    "\n",
    "t_max_step = 15\n",
    "c_ts_length = 5\n",
    "c_forecast_length = 5\n",
    "\n",
    "for i in range(num_epochs):\n",
    "  x_data = data_dist.sample([batch_size])\n",
    "  x_noise, traj_forward = diffusion_sigrnn.forward_sample(x_data)\n",
    "  traj_forward = traj_forward.to(device)\n",
    "  traj_forward_flip = torch.fliplr(traj_forward)\n",
    "\n",
    "  for j in range(n_Gstep_per_Dstep):\n",
    "    with torch.no_grad():\n",
    "      noise = torch.randn([batch_size,1]).to(device) # [N, d=1]\n",
    "      # x_gen, traj_back = diffusion_sigrnn.backward_sample(x_noise.to(device), generator)\n",
    "      x_gen, traj_back = diffusion_sigrnn.backward_sample_example(traj_forward.to(device), generator)\n",
    "      traj_back = traj_back.to(device)\n",
    "      ts = torch.randint(t_max_step, (c_ts_length,))\n",
    "      x_real=traj_forward_flip.view([-1,total_steps+1, 1])\n",
    "      x_fake = traj_back.view([-1, c_total_steps+1, 1])\n",
    "\n",
    "    G_loss = 0\n",
    "    for t1 in ts:\n",
    "      ratio = total_steps / c_total_steps\n",
    "      t1_real = int(t1*ratio)\n",
    "      t1_real_forecast = int((t1+c_forecast_length)*ratio)\n",
    "      # print(f't1_real={t1_real}, t1_real_forecast={t1_real_forecast}')\n",
    "      # print(f't1={t1_real}, t1+c_forecast_length={t1+c_forecast_length}')\n",
    "      G_loss = G_loss + pcf.distance_measure(x_real[:, t1_real:t1_real_forecast+1],\n",
    "                                             x_fake[:, t1:t1+c_forecast_length+1], Lambda=0.1)\n",
    "    G_loss = G_loss/ts_length\n",
    "    G_opt.zero_grad()\n",
    "    G_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(generator.parameters(), 0.05)\n",
    "    G_opt.step()\n",
    "    pcf.eval()  # set PCF model to evaluation mode\n",
    "    print(j,  G_loss.item())\n",
    "\n",
    "  # train the PCF network as a discriminator. We want PCF has a great ability to distinguish the real data and the generated data.\n",
    "  # so we train the PCF to maximise the distance between the real data and the generated data.\n",
    "  for j in range(n_Dstep_per_Gstep):\n",
    "    with torch.no_grad():\n",
    "      x_data = data_dist.sample([batch_size])\n",
    "      x_noise, traj_forward = diffusion_sigrnn.forward_sample(x_data)\n",
    "      traj_forward = traj_forward.to(device)\n",
    "      noise = torch.randn([batch_size, 1]).to(device)\n",
    "      x_gen, traj_back = diffusion_sigrnn.backward_sample(noise, generator)\n",
    "      traj_back = traj_back.to(device)\n",
    "    traj_forward_flip = torch.fliplr(traj_forward)\n",
    "    x_real=traj_forward_flip.view([-1,total_steps+1, 1])\n",
    "    x_fake = traj_back.view([-1, c_total_steps+1, 1])\n",
    "\n",
    "    pcf.train()  # set PCF model to training mode\n",
    "    ts = torch.randint(t_max_step, (c_ts_length,))\n",
    "    D_loss = 0\n",
    "    for t1 in ts:\n",
    "      ratio = total_steps / c_total_steps\n",
    "      t1_real = int(t1 * ratio)\n",
    "      t1_real_forecast = int((t1+c_forecast_length)* ratio)\n",
    "      D_loss = D_loss - pcf.distance_measure(x_real[:, t1_real:t1_real_forecast+1],\n",
    "                                             x_fake[:, t1:t1+c_forecast_length+1], Lambda=0.1)\n",
    "    D_loss = D_loss/ts_length\n",
    "    D_opt.zero_grad()\n",
    "    D_loss.backward()\n",
    "    D_opt.step()\n",
    "\n",
    "    pcf.eval()  # set PCF model to evaluation mode\n",
    "    print(j, D_loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poor performance\n",
    "class sigRNNGenerator(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, num_layers, output_dim=1):\n",
    "    super(sigRNNGenerator, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.num_layers = num_layers\n",
    "    self.output_dim = output_dim\n",
    "    self.rnn = nn.Sequential(FFN(input_dim = hidden_dim+1+2*input_dim,\n",
    "                                  output_dim = hidden_dim,\n",
    "                                  hidden_dims = [hidden_dim, hidden_dim]),  # Two hidden layers, each with hidden_dim units\n",
    "                                  nn.SiLU()\n",
    "                            )\n",
    "    self.linear = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "    self.initial_nn = nn.Sequential(ResFNN(input_dim=input_dim,\n",
    "                                            output_dim=hidden_dim,\n",
    "                                            hidden_dims=[hidden_dim, hidden_dim]),\n",
    "                                    nn.SiLU()\n",
    "                                    )\n",
    "\n",
    "  def forward(self, batch_size, c_total_steps, c_dt, noise): # noise: [N,d=1]\n",
    "    h = self.initial_nn(noise) # [N, hidden_dim]\n",
    "    x = torch.zeros(batch_size, c_total_steps, self.output_dim)  # [N,c_T,output_dim=1]\n",
    "    c_times = torch.linspace(c_dt,1,c_total_steps)\n",
    "\n",
    "    for idx,t in enumerate(reversed(c_times)):\n",
    "      eps = self.sample_eps(batch_size, c_dt) # [N, 2*d=2]\n",
    "      h = self.rnn(torch.cat([h, torch.tensor([t]).expand(batch_size,1), eps], -1))  # [N, hid+1+2*in]\n",
    "      x[:,idx,:] = self.linear(h)   # [N,output_dim=1]\n",
    "    return x # [N,c_T,output_dim=1]\n",
    "\n",
    "  def sample_eps(self, batch_size, c_dt):\n",
    "    # generate i.i.d. d=input_dim joint Gaussian rvs with defined covariance matrix\n",
    "    eps = []\n",
    "    for _ in range(self.input_dim):\n",
    "      cov_matrix = torch.tensor([[c_dt, (c_dt**2/2)],\n",
    "                                 [(c_dt**2/2), (c_dt**3/3)]])\n",
    "      m = MultivariateNormal(loc=torch.zeros(2), covariance_matrix=cov_matrix)\n",
    "      eps_i = m.sample((batch_size,))\n",
    "      eps.append(eps_i)\n",
    "    eps = torch.cat(eps, dim=1) # [N, 2*input_dim]\n",
    "    return eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poor performance\n",
    "class RNNGenerator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim=1):\n",
    "      super(RNNGenerator, self).__init__()\n",
    "      self.input_dim = input_dim\n",
    "      self.hidden_dim = hidden_dim\n",
    "      self.num_layers = num_layers\n",
    "      self.output_dim = output_dim\n",
    "      self.linear = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "      self.initial_nn = nn.Sequential(ResFNN(input_dim=input_dim,\n",
    "                                             output_dim=hidden_dim,\n",
    "                                             hidden_dims=[hidden_dim, hidden_dim]),\n",
    "                                      nn.SiLU()\n",
    "                                      )\n",
    "      self.rnn = nn.RNN(input_size=2*input_dim,hidden_size=hidden_dim,num_layers=num_layers,batch_first=True)\n",
    "\n",
    "    def forward(self, batch_size, c_total_steps, c_dt, noise): # noise: [N,d=1]\n",
    "      h = torch.randn(self.num_layers, batch_size, self.rnn.hidden_size)# [N, hidden_dim]\n",
    "      input_seq = self.sample_eps(batch_size, c_total_steps, c_dt) # [N, c_T, 2*input_dim]\n",
    "      out,_ = self.rnn(input_seq,h)\n",
    "      x = self.linear(out)\n",
    "      return x # [N,c_T,output_dim=1]\n",
    "\n",
    "    def sample_eps(self, batch_size, c_total_steps, c_dt):\n",
    "      # generate i.i.d. d=input_dim joint Gaussian rvs with defined covariance matrix\n",
    "      eps = [] # [N, c_T, 2*input_dim]\n",
    "      print(f\"input_dim: {self.input_dim}, c_total_steps: {c_total_steps}, c_dt: {c_dt}\")\n",
    "      for t in range(c_total_steps):\n",
    "        eps_t = []  # [N,1,2*input_dim]\n",
    "        for _ in range(self.input_dim):\n",
    "          cov_matrix = torch.tensor([[c_dt, (c_dt**2/2)],\n",
    "                                  [(c_dt**2/2), (c_dt**3/3)]])\n",
    "          m = MultivariateNormal(loc=torch.zeros(2), covariance_matrix=cov_matrix)\n",
    "          eps_i = m.sample((batch_size,)) # [N,2]\n",
    "          eps_t.append(eps_i)\n",
    "        eps_t = torch.cat(eps_t, dim=1).unsqueeze(1) # [N,2*input_dim] -> [N,1,2*input_dim]\n",
    "        eps.append(eps_t) \n",
    "      eps = torch.cat(eps,dim=1)\n",
    "      print(f\"eps shape: {eps.shape}\")\n",
    "      return eps # [N, c_T, 2*input_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poor performance\n",
    "class SigRNNDiffusion(DiffusionProcess):\n",
    "    def __init__(self, sde_type=\"VP\",\n",
    "                 sde_info={\"VP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"subVP\": {\"beta_min\": 0.1, \"beta_max\": 20},\n",
    "                           \"VE\": {\"sigma_min\": 0.01, \"sigma_max\": 50}},\n",
    "                 c_total_steps = 20,\n",
    "                 **kwargs):\n",
    "        super(SigRNNDiffusion, self).__init__(**kwargs)\n",
    "        assert self.discrete is False, \"DDPM is only for continuous data\"\n",
    "        self.c_total_steps = c_total_steps\n",
    "        self.dt = 1. / self.total_steps # step size\n",
    "        self.c_dt = 1. / self.c_total_steps\n",
    "        self.sde = SDE(self.total_steps, sde_type, sde_info)\n",
    "\n",
    "    def forward_one_step(self, x_prev, t):\n",
    "        \"\"\"\n",
    "        Discretized forward SDE process for actual compuatation:\n",
    "        x_{t+1} = x_t + f_t(x_t) * dt + G_t * z_t * sqrt(dt)\n",
    "        \"\"\"\n",
    "        f_t, g_t = self.sde.drifts(x_prev, t-1)\n",
    "        z = torch.randn_like(x_prev)\n",
    "        x_t = x_prev + f_t * self.dt + g_t * z * np.sqrt(self.dt)\n",
    "        return x_t # [N]\n",
    "\n",
    "    def forward_sample(self, data): # data: torch.tensor, shape=[N]\n",
    "        trajs = torch.zeros([len(data), self.total_steps+1]) # [N,T+1]\n",
    "        x = data.to(device) # [N]\n",
    "        trajs[:, 0] = x\n",
    "        for t in range(1, self.total_steps+1):\n",
    "            x = self.forward_one_step(x, t) # [N]\n",
    "            trajs[:, t] = x\n",
    "        return x, trajs # [N]:the last step, [N,T+1]\n",
    "\n",
    "    # def backward_one_step(self, x_t, t, pred_score, clip_denoised=True):\n",
    "    #     \"\"\"\n",
    "    #     Discretized backward SDE process for actual compuatation:\n",
    "    #     x_{t-1} = x_t - (f_t(x_t) - (G_t)^2 * pred_score) * dt + G_t * z_t * sqrt(dt)\n",
    "    #     \"\"\"\n",
    "    #     z = torch.randn_like(x_t).to(device) # [N,d=1]\n",
    "    #     f_t, g_t = self.sde.drifts(x_t, t)\n",
    "    #     f_t = f_t.to(device)\n",
    "    #     x_prev = x_t - (f_t - g_t**2 * pred_score) * self.dt + g_t * z * np.sqrt(self.dt)\n",
    "    #     if clip_denoised and x_t.ndim > 2:\n",
    "    #         print('backward_one_step')\n",
    "    #         x_prev.clamp_(-1., 1.)\n",
    "    #     return x_prev # [N,d=1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, noise, generator):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        x_t = noise.to(generator.linear.weight.device) # [N,d=1]\n",
    "        pred_trajs = generator(batch_size=x_t.shape[0], c_total_steps=self.c_total_steps, c_dt=self.c_dt, noise=x_t) # [N,c_T,d=1]\n",
    "        pred_trajs = torch.reshape(torch.cat((x_t.unsqueeze(1), pred_trajs), dim=1),(x_t.shape[0],-1))  # [N,c_T+1,d=1] -> [N,(c_T+1)*(d=1)]\n",
    "        x_gen = pred_trajs[:,-1] # [N,d=1]\n",
    "        return x_gen, torch.reshape(pred_trajs,(x_t.shape[0],-1)) # [N,d=1], [N,(c_T+1)*(d=1)]\n",
    "\n",
    "    def backward_sample(self, noise, generator):\n",
    "        \"\"\"\n",
    "        Sample from backward diffusion process\n",
    "        \"\"\"\n",
    "        x_t = noise.to(generator.linear.weight.device) # [N,d=1]\n",
    "        pred_trajs = generator(batch_size=x_t.shape[0], c_total_steps=self.c_total_steps, c_dt=self.c_dt, noise=x_t) # [N,c_T,d=1]\n",
    "        pred_trajs = torch.reshape(torch.cat((x_t.unsqueeze(1), pred_trajs), dim=1),(x_t.shape[0],-1))  # [N,c_T+1,d=1] -> [N,(c_T+1)*(d=1)]\n",
    "        x_gen = pred_trajs[:,-1] # [N,d=1]\n",
    "        return x_gen, torch.reshape(pred_trajs,(x_t.shape[0],-1)) # [N,d=1], [N,(c_T+1)*(d=1)]\n",
    "\n",
    "    # def backward_sample_example(self, noise, net):\n",
    "    #     \"\"\"\n",
    "    #     Sample from backward diffusion process\n",
    "    #     noise: torch.tensor, shape=[num_paths, T]\n",
    "    #     \"\"\"\n",
    "    #     # noise_start = noise[:, 0]\n",
    "    #     noise_end = noise[:, -1]\n",
    "    #     # trajs = [noise_end]\n",
    "    #     trajs = torch.zeros_like(noise)\n",
    "    #     trajs[:, -1] = noise_end\n",
    "    #     for t in reversed(range(1, self.total_steps+1)):\n",
    "    #         pred_score = net(noise[:,t].unsqueeze(1), t) # [N,d=1]\n",
    "    #         x_t = self.backward_one_step(noise[:,t].unsqueeze(1), t, pred_score)\n",
    "    #         trajs[:,t-1] = x_t.squeeze()\n",
    "    #     return x_t, trajs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
